---
title: "Anlyzing Multifurcating Trajectories with `tradeSeq`"
subtitle: "University of Florida - Dept. of Biostatistics - Bacher Group"
author: "Jack Leary"
date: "`r Sys.Date()`"
output:
  html_document:
    theme: yeti
    highlight: tango
    code_folding: show
    code_download: true
    toc: true
    toc_float:
      collpased: false
    df_print: kable
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                      comment = NA, 
                      message = FALSE, 
                      warning = FALSE, 
                      fig.align = "center")
set.seed(312)  # lucky seed
```

# Libraries

```{r, message=FALSE, warning=FALSE, results='hide'}
library(dplyr)
library(purrr)
library(irlba)
library(foreach)
library(parallel)
library(tradeSeq)
library(slingshot)
library(doParallel)
rename <- dplyr::rename
```

# Load Multifurcating Datasets

Here we'll read in 10 datasets generated using the `dyntoy` package taken from [the tradeSeqPaper repo on GitHub](https://github.com/statOmics/tradeSeqPaper/tree/master/simulation/sim2_dyntoy_multifurcating_4/multiple/datasets). 

```{r}
ts_mf_dir <- "~/Desktop/UF Biostatistics/Capstone/tradeSeqPaper/simulation/sim2_dyntoy_multifurcating_4/multiple/datasets/"
ts_mf_list <- map(paste0(ts_mf_dir, list.files(ts_mf_dir)), readRDS)
names(ts_mf_list) <- paste0("dyntoy_", gsub("\\.rds", "", gsub(".*_", "", list.files(ts_mf_dir))))
```

# Process Data & Run `tradeSeq`

We'll need to define the following function to perform quantile normalization as the `tradeSeq` authors did (see [here](https://github.com/statOmics/tradeSeqPaper/blob/master/simulation/sim2_dyntoy_multifurcating_4/20190326_evaluateDyntoyMultifurcating4.Rmd)). While `tradeSeq` uses raw expression as the response variable in its GAMs, calculating pseudotime using `slingshot` requires principal components and clusters as input, and thus we'll need to process the raw counts a bit first. 

```{r}
FQnorm <- function(counts) {
  rk <- apply(counts, 2, rank, ties.method = "min")
  counts.sort <- apply(counts, 2, sort)
  refdist <- apply(counts.sort, 1, median)
  norm <- apply(rk, 2, function(r) { refdist[r] })
  rownames(norm) <- rownames(counts)
  return(norm)
}
```

Now we'll loop through each of the 10 datasets (in parallel using `foreach`) and process them in the same way. We use `tradeSeq`'s `evaluateK()` function to adaptively determine how many knots should be used in each GAM by choosing the value of $k$ with the lowest average AIC. 

```{r}
cl <- makeCluster(4)
registerDoParallel(cl)
clusterSetRNGStream(cl, 312)
ts_res_all <- foreach(i = 1:length(ts_mf_list), 
                      .combine = "list", 
                      .multicombine = TRUE, 
                      .maxcombine = length(ts_mf_list), 
                      .export = c("FQnorm", "ts_mf_list"),
                      .packages = c("tradeSeq", "slingshot", "irlba", "bluster", "igraph")) %dopar% {
  ts_counts_norm <- FQnorm(t(ts_mf_list[[i]]$counts))
  ts_pca <- prcomp_irlba(t(ts_counts_norm), n = 3, scale. = FALSE)
  ts_graph <- makeSNNGraph(ts_pca$x, k = 30, type = "jaccard")
  ts_cl <- cluster_louvain(graph = ts_graph)$membership
  ts_lineage <- getLineages(ts_pca$x, clusterLabels = ts_cl)
  ts_crv <- getCurves(ts_lineage)
  ts_cell_weights <- slingCurveWeights(ts_crv)
  ts_pt <- slingPseudotime(ts_crv, na = FALSE)
  k_vals <- c(3:8)
  icMat <- evaluateK(counts = t(ts_mf_list[[i]]$counts),  
                     pseudotime = ts_pt, 
                     cellWeights = ts_cell_weights,
                     nGenes = 500, 
                     k = k_vals, 
                     verbose = FALSE)
  k_to_use <- k_vals[which.min(colMeans(icMat))]
  ts_gam <- fitGAM(t(ts_mf_list[[i]]$counts), 
                   pseudotime = ts_pt, 
                   cellWeights = ts_cell_weights, 
                   nknots = k_to_use, 
                   verbose = FALSE)
  ts_gam
}
stopCluster(cl)
names(ts_res_all) <- names(ts_mf_list)
```

Next we'll need to run `tradeSeq::associationTest()` on each GAM to determine whether genes are differentially expressed. We define "differentially expressed" here as the global $p$-value being less than 0.01 after adjustment using the Bonferroni correction. 

```{r}
ts_asso_test_list <- map2(.x = ts_res_all, 
                          .y = ts_mf_list, 
                          ~ associationTest(.x) %>% bind_cols(.y$tde_overall$differentially_expressed))
ts_asso_test_df <- reduce(ts_asso_test_list, bind_rows) %>% 
                   mutate(dataset = rep(names(ts_mf_list), each = 5000)) %>% 
                   setNames(nm = c("wald_stat", "df", "pvalue", "mean_log_fc", "true_de", "dataset")) %>% 
                   arrange(pvalue) %>% 
                   mutate(pvalue_adj = p.adjust(pvalue, method = "bonferroni"), 
                          ts_de = case_when(pvalue_adj < 0.01 ~ TRUE, TRUE ~ FALSE))
```

Let's check out the predictive results. 

```{r}
caret::confusionMatrix(data = as.factor(ts_asso_test_df$ts_de), 
                       reference = as.factor(ts_asso_test_df$true_de), 
                       positive = "TRUE")
```

# DE Testing Over Multiple Lineages with `scLANE`

This is a test case with just one dataset until I get all the functions working. 

```{r}
scl_counts_norm <- FQnorm(t(ts_mf_list[[1]]$counts))
scl_pca <- prcomp_irlba(t(scl_counts_norm), n = 3, scale. = FALSE)
scl_graph <- bluster::makeSNNGraph(scl_pca$x, k = 30, type = "jaccard")
scl_cl <- igraph::cluster_louvain(graph = scl_graph)$membership
scl_lineage <- getLineages(scl_pca$x, clusterLabels = scl_cl)
scl_crv <- getCurves(scl_lineage)
scl_cell_weights <- slingCurveWeights(scl_crv)
scl_pt <- slingPseudotime(scl_crv)
```

# Development Area 

```{r}
library(scLANE)
pt_df <- as.data.frame(scl_pt) %>% 
         rename(L_One = curve1, L_Two = curve2) %>% 
         mutate(across(everything(), function(x) x / max(x, na.rm = TRUE)))
sim_counts <- ts_mf_list[[1]]$counts
set.seed(312)
samp_idx <- sample(1:ncol(sim_counts), 10)
gene_stats <- testDynamic(expr.mat = sim_counts[, samp_idx], 
                          pt = pt_df, 
                          parallel.exec = TRUE, 
                          n.cores = 2, 
                          track.time = TRUE)
```

```{r}
global_test_results <- getResultsDE(gene_stats)
global_test_results
```


slope test

```{r}
slope_test_results <- testSlope(dyn.results = gene_stats)
slope_test_results
```

plot models 

```{r}

```

# Run `scLANE` on All Ten Datasets

```{r}
scl_res_list <- vector("list", length(ts_mf_list))
for (i in seq(ts_mf_list)) {
  scl_counts_norm <- FQnorm(t(ts_mf_list[[i]]$counts))
  scl_pca <- prcomp_irlba(t(scl_counts_norm), n = 3, scale. = FALSE)
  scl_graph <- bluster::makeSNNGraph(scl_pca$x, k = 30, type = "jaccard")
  scl_cl <- igraph::cluster_louvain(graph = scl_graph)$membership
  scl_lineage <- getLineages(scl_pca$x, clusterLabels = scl_cl)
  scl_crv <- getCurves(scl_lineage)
  scl_cell_weights <- slingCurveWeights(scl_crv)
  scl_pt <- slingPseudotime(scl_crv, na = FALSE)
  pt_df <- as.data.frame(scl_pt) %>% 
           setNames(nm = unlist(map(LETTERS[1:ncol(.)], function(.x) paste0("Lineage_", .x)))) %>%  # adaptively names lineage columns WITHOUT numbers
           mutate(across(everything(), function(x) x / max(x, na.rm = TRUE)))
  gene_stats <- testDynamic(expr.mat = ts_mf_list[[i]]$counts, 
                            pt = pt_df, 
                            parallel.exec = TRUE, 
                            n.cores = 6, 
                            track.time = TRUE)
  scl_res_list[[i]] <- gene_stats
  rm(gene_stats)
}
```

```{r}
global_res_list <- map(scl_res_list, getResultsDE)
for (i in seq(global_res_list)) { 
  global_res_list[[i]] <- global_res_list[[i]] %>% 
                          mutate(Dataset = names(ts_mf_list)[i]) %>% 
                          left_join(ts_mf_list[[i]]$tde_overall, by = c("Gene" = "feature_id")) %>% 
                          mutate(True_DE_Ind = case_when(differentially_expressed ~ 1, TRUE ~ 0))
}
global_res_df <- reduce(global_res_list, rbind)
```

Let's check out our overall prediction metrics. 

```{r}
global_res_de_sum <- global_res_df %>% 
                     select(Gene, Dataset, Gene_Dynamic_Overall, True_DE_Ind) %>% 
                     distinct()
caret::confusionMatrix(data = as.factor(global_res_de_sum$Gene_Dynamic_Overall), 
                       reference = as.factor(global_res_de_sum$True_DE_Ind), 
                       positive = "1")
```

