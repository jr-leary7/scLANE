---
title: "Anlyzing Multifurcating Trajectories with `tradeSeq`"
subtitle: "University of Florida - Dept. of Biostatistics - Bacher Group"
author: "Jack Leary"
date: "`r Sys.Date()`"
output:
  html_document:
    theme: yeti
    highlight: tango
    code_folding: show
    code_download: true
    toc: true
    toc_float:
      collpased: false
    df_print: kable
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                      comment = NA, 
                      message = FALSE, 
                      warning = FALSE, 
                      fig.align = "center")
set.seed(312)  # lucky seed
```

# Libraries

```{r, message=FALSE, warning=FALSE, results='hide'}
library(dplyr)
library(purrr)
library(irlba)
library(foreach)
library(parallel)
library(tradeSeq)
library(slingshot)
library(doParallel)
rename <- dplyr::rename
```

# Load Multifurcating Datasets

Here we'll read in 10 datasets generated using the `dyntoy` package taken from [the tradeSeqPaper repo on GitHub](https://github.com/statOmics/tradeSeqPaper/tree/master/simulation/sim2_dyntoy_multifurcating_4/multiple/datasets). 

```{r}
ts_mf_dir <- "~/Desktop/UF Biostatistics/Capstone/tradeSeqPaper/simulation/sim2_dyntoy_multifurcating_4/multiple/datasets/"
ts_mf_list <- map(paste0(ts_mf_dir, list.files(ts_mf_dir)), readRDS)
names(ts_mf_list) <- paste0("dyntoy_", gsub("\\.rds", "", gsub(".*_", "", list.files(ts_mf_dir))))
```

Let's examine the counts distribution of each dataset. 

```{r}
nonzero_counts <- map(ts_mf_list, function(x) sum(x$counts > 0))
zero_counts <- map(ts_mf_list, function(x) sum(x$counts == 0))
reduce(zero_counts, `+`) / reduce(nonzero_counts, `+`)
count_sum <- map(ts_mf_list, function(x) sum(x$counts)) %>% reduce(`+`)
n_elem <- map(ts_mf_list, function(x) nrow(x$counts) * ncol(x$counts)) %>% reduce(`+`)
count_sum / n_elem
```

# Process Data & Run `tradeSeq`

We'll need to define the following function to perform quantile normalization as the `tradeSeq` authors did (see [here](https://github.com/statOmics/tradeSeqPaper/blob/master/simulation/sim2_dyntoy_multifurcating_4/20190326_evaluateDyntoyMultifurcating4.Rmd)). While `tradeSeq` uses raw expression as the response variable in its GAMs, calculating pseudotime using `slingshot` requires principal components and clusters as input, and thus we'll need to process the raw counts a bit first. 

```{r}
FQnorm <- function(counts) {
  rk <- apply(counts, 2, rank, ties.method = "min")
  counts.sort <- apply(counts, 2, sort)
  refdist <- apply(counts.sort, 1, median)
  norm <- apply(rk, 2, function(r) { refdist[r] })
  rownames(norm) <- rownames(counts)
  return(norm)
}
```

Let's examine the distribution of the simulated counts: 

```{r}
library(ggplot2)
map(ts_mf_list, function(x) x$counts) %>% 
  reduce(rbind) %>% 
  as.data.frame() %>% 
  tidyr::pivot_longer(cols = everything(), values_to = "N") %>% 
  ggplot(aes(x = N)) + 
  geom_histogram(color = "black", fill = "deepskyblue4", alpha = 0.75) + 
  scale_y_continuous(labels = scales::comma_format()) + 
  scale_x_continuous(labels = scales::comma_format()) + 
  labs(x = "Expression", y = "Count") + 
  theme_classic(base_size = 14)
```

Now we'll loop through each of the 10 datasets (in parallel using `foreach`) and process them in the same way. We use `tradeSeq`'s `evaluateK()` function to adaptively determine how many knots should be used in each GAM by choosing the value of $k$ with the lowest average AIC. Then we'll need to run `tradeSeq::associationTest()` on each GAM to determine whether genes are differentially expressed. We define "differentially expressed" here as the global $p$-value being less than 0.01 after adjustment using the Bonferroni correction. 

```{r}
start_time_ts <- Sys.time()
cl <- makeCluster(4)
registerDoParallel(cl)
clusterSetRNGStream(cl, 312)
ts_res_all <- foreach(i = 1:length(ts_mf_list), 
                      .combine = "list", 
                      .multicombine = TRUE, 
                      .maxcombine = length(ts_mf_list), 
                      .export = c("FQnorm", "ts_mf_list"),
                      .packages = c("tradeSeq", "slingshot", "irlba", "bluster", "igraph")) %dopar% {
  ts_counts_norm <- FQnorm(t(ts_mf_list[[i]]$counts))
  ts_pca <- prcomp_irlba(t(ts_counts_norm), n = 3, scale. = FALSE)
  ts_graph <- makeSNNGraph(ts_pca$x, k = 30, type = "jaccard")
  ts_cl <- cluster_louvain(graph = ts_graph)$membership
  ts_lineage <- getLineages(ts_pca$x, clusterLabels = ts_cl)
  ts_crv <- getCurves(ts_lineage)
  ts_cell_weights <- slingCurveWeights(ts_crv)
  ts_pt <- slingPseudotime(ts_crv, na = FALSE)
  k_vals <- c(3:8)
  icMat <- evaluateK(counts = t(ts_mf_list[[i]]$counts),  
                     pseudotime = ts_pt, 
                     cellWeights = ts_cell_weights,
                     nGenes = 500, 
                     k = k_vals, 
                     verbose = FALSE)
  k_to_use <- k_vals[which.min(colMeans(icMat))]
  ts_gam <- fitGAM(t(ts_mf_list[[i]]$counts), 
                   pseudotime = ts_pt, 
                   cellWeights = ts_cell_weights, 
                   nknots = k_to_use, 
                   verbose = FALSE)
  ts_gam$k <- k_to_use
  ts_gam
}
stopCluster(cl)
names(ts_res_all) <- names(ts_mf_list)

ts_asso_test_list <- map2(.x = ts_res_all, 
                          .y = ts_mf_list, 
                          ~ associationTest(.x) %>% bind_cols(.y$tde_overall$differentially_expressed))
ts_asso_test_df <- reduce(ts_asso_test_list, bind_rows) %>% 
                   mutate(dataset = rep(names(ts_mf_list), each = 5000)) %>% 
                   setNames(nm = c("wald_stat", "df", "pvalue", "mean_log_fc", "true_de", "dataset")) %>% 
                   arrange(pvalue) %>% 
                   mutate(pvalue_adj = p.adjust(pvalue, method = "bonferroni"), 
                          ts_de = case_when(pvalue_adj < 0.01 ~ TRUE, TRUE ~ FALSE))
end_time_ts <- Sys.time()
end_time_ts - start_time_ts
```

Let's check out the predictive results. 

```{r}
caret::confusionMatrix(data = as.factor(ts_asso_test_df$ts_de), 
                       reference = as.factor(ts_asso_test_df$true_de), 
                       positive = "TRUE")
```

# Run `scLANE` on All Ten Datasets

```{r}
library(scLANE)
start_time <- Sys.time()
scl_res_list <- vector("list", length(ts_mf_list))
for (i in seq(ts_mf_list)) {
  scl_counts_norm <- FQnorm(t(ts_mf_list[[i]]$counts))
  scl_pca <- prcomp_irlba(t(scl_counts_norm), n = 3, scale. = FALSE)
  scl_graph <- bluster::makeSNNGraph(scl_pca$x, k = 30, type = "jaccard")
  scl_cl <- igraph::cluster_louvain(graph = scl_graph)$membership
  scl_lineage <- getLineages(scl_pca$x, clusterLabels = scl_cl)
  scl_crv <- getCurves(scl_lineage)
  scl_cell_weights <- slingCurveWeights(scl_crv)
  scl_pt <- slingPseudotime(scl_crv, na = FALSE)
  pt_df <- as.data.frame(scl_pt) %>% 
           mutate(across(everything(), function(x) x / max(x, na.rm = TRUE)))
  gene_stats <- testDynamic(expr.mat = ts_mf_list[[i]]$counts, 
                            pt = pt_df, 
                            parallel.exec = TRUE, 
                            n.cores = 6, 
                            track.time = TRUE)
  scl_res_list[[i]] <- gene_stats
  rm(gene_stats)
}
end_time_td <- Sys.time()
global_res_list <- map(scl_res_list, getResultsDE)
for (i in seq(global_res_list)) { 
  global_res_list[[i]] <- global_res_list[[i]] %>% 
                          mutate(Dataset = names(ts_mf_list)[i]) %>% 
                          left_join(ts_mf_list[[i]]$tde_overall, by = c("Gene" = "feature_id")) %>% 
                          mutate(True_DE_Ind = case_when(differentially_expressed ~ 1, TRUE ~ 0))
}
global_res_df <- reduce(global_res_list, rbind)
end_time <- Sys.time()
end_time - start_time
```

Let's check out our overall prediction metrics. 

```{r}
global_res_de_sum <- global_res_df %>% 
                     select(Gene, Dataset, Gene_Dynamic_Overall, True_DE_Ind) %>% 
                     distinct()
caret::confusionMatrix(data = as.factor(global_res_de_sum$Gene_Dynamic_Overall), 
                       reference = as.factor(global_res_de_sum$True_DE_Ind), 
                       positive = "1")
```

# Save Data 

```{r}
saveRDS(scl_res_list, file = "~/Desktop/multifurcating_scLANE_res.Rds")
saveRDS()
```



# Dev Area

This is a test case with just one dataset until I get all the functions working. 

```{r}
scl_counts_norm <- FQnorm(t(ts_mf_list[[1]]$counts))
scl_pca <- prcomp_irlba(t(scl_counts_norm), n = 3, scale. = FALSE)
scl_graph <- bluster::makeSNNGraph(scl_pca$x, k = 30, type = "jaccard")
scl_cl <- igraph::cluster_louvain(graph = scl_graph)$membership
scl_lineage <- getLineages(scl_pca$x, clusterLabels = scl_cl)
scl_crv <- getCurves(scl_lineage)
scl_cell_weights <- slingCurveWeights(scl_crv)
scl_pt <- slingPseudotime(scl_crv)
```

```{r}
library(glm2)
pt_df <- data.frame(PT_A = scl_pt[!is.na(scl_pt[, 2]), 2])
marge_mod <- scLANE::marge2(X_pred = pt_df, 
                            Y = ts_mf_list[[1]]$counts[!is.na(scl_pt[, 2]), "G2730"],
                            M = 5)
init_th <- mvabund::manyglm(ts_mf_list[[1]]$counts[!is.na(scl_pt[, 2]), "G2730"] ~ pt_df[, 1], family = "negative.binomial", maxiter = 1000, maxiter2 = 100)$theta
glm_mod <- MASS::glm.nb(ts_mf_list[[1]]$counts[!is.na(scl_pt[, 2]), "G2730"] ~ ., pt_df, init.theta = as.numeric(init_th))
gam_mod <- scLANE::nbGAM(expr = ts_mf_list[[1]]$counts[!is.na(scl_pt[, 2]), "G2730"], pt = pt_df)
predict(glm_mod, se.fit = TRUE) %>% 
  as.data.frame() %>% 
  select(-residual.scale) %>% 
  mutate(PT = pt_df[, 1], 
         EXP = ts_mf_list[[1]]$counts[!is.na(scl_pt[, 2]), "G2730"]) %>% 
  ggplot(aes(x = PT, y = EXP)) + 
  geom_point() + 
  geom_line(aes(x = PT, y = exp(fit)), color = "red") + 
  geom_ribbon(aes(x = PT, ymin = exp(fit + 1.96 * se.fit), ymax = exp(fit - 1.96 * se.fit)), color = "blue", fill = "blue", alpha = 0.5) + 
  theme_classic()

predict(gam_mod, se.fit = TRUE) %>% 
  as.data.frame() %>% 
  mutate(PT = pt_df[, 1], 
         EXP = ts_mf_list[[1]]$counts[!is.na(scl_pt[, 1]), "G2730"]) %>% 
  ggplot(aes(x = PT, y = EXP)) + 
  geom_point() + 
  geom_line(aes(x = PT, y = exp(fit)), color = "red") + 
  geom_ribbon(aes(x = PT, ymin = exp(fit + 1.96 * se.fit), ymax = exp(fit - 1.96 * se.fit)), color = "blue", fill = "blue", alpha = 0.5)

marge_mod$final_mod %>% 
  predict(se.fit = TRUE) %>% 
  as.data.frame() %>% 
  bind_cols(gam_mod %>% predict(se.fit = TRUE) %>% as.data.frame()) %>% 
  bind_cols(glm_mod %>% predict(se.fit = TRUE) %>% as.data.frame() %>% select(-residual.scale)) %>% 
  select(-residual.scale) %>% 
  set_names(c("MARGE_fit", "MARGE_SE", "GAM_fit", "GAM_SE", "GLM_fit", "GLM_SE")) %>% 
  View()
gam_mod %>% predict(se.fit = TRUE) %>% as.data.frame() %>% View()
```


```{r}
library(scLANE)
pt_df <- as.data.frame(scl_pt) %>% 
         mutate(across(everything(), function(x) x / max(x, na.rm = TRUE)))
sim_counts <- ts_mf_list[[1]]$counts
set.seed(312)
samp_idx <- sample(1:ncol(sim_counts), 10)
gene_stats <- testDynamic(expr.mat = sim_counts[, samp_idx], 
                          pt = pt_df, 
                          parallel.exec = TRUE, 
                          n.cores = 2, 
                          track.time = TRUE)
```

```{r}
global_test_results <- getResultsDE(gene_stats)
global_test_results
```


slope test

```{r}
slope_test_results <- testSlope(dyn.results = gene_stats)
slope_test_results
```


```{r}
library(glm2)
plotModels(test.dyn.res = gene_stats, 
           gene = "G2730", 
           pt = (as.data.frame(scl_pt) %>% 
                 mutate(across(everything(), function(x) x / max(x, na.rm = TRUE)))), 
           gene.counts = sim_counts) + 
  ggplot2::scale_color_manual(values = MetBrewer::met.brewer("Juarez")) + 
  ggplot2::scale_fill_manual(values = MetBrewer::met.brewer("Juarez"))
```
