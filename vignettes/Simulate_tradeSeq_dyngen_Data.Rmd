---
title: "Anlyzing Multifurcating Trajectories with `tradeSeq`"
subtitle: "University of Florida - Dept. of Biostatistics - Bacher Group"
author: "Jack Leary"
date: "`r Sys.Date()`"
output:
  html_document:
    theme: yeti
    highlight: tango
    code_folding: show
    code_download: true
    toc: true
    toc_float:
      collpased: false
    df_print: kable
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                      comment = NA, 
                      message = FALSE, 
                      warning = FALSE, 
                      fig.align = "center")
set.seed(312)  # lucky seed
```

# Libraries

```{r}
library(dplyr)
library(purrr)
library(irlba)
library(foreach)
library(parallel)
library(tradeSeq)
library(slingshot)
library(doParallel)
rename <- dplyr::rename
```

# Load Multifurcating Datasets

Here we'll read in 10 datasets generated using the `dyntoy` package taken from [the tradeSeqPaper repo on GitHub](https://github.com/statOmics/tradeSeqPaper/tree/master/simulation/sim2_dyntoy_multifurcating_4/multiple/datasets). 

```{r}
ts_mf_dir <- "~/Desktop/UF Biostatistics/Capstone/tradeSeqPaper/simulation/sim2_dyntoy_multifurcating_4/multiple/datasets/"
ts_mf_list <- map(paste0(ts_mf_dir, list.files(ts_mf_dir)), readRDS)
names(ts_mf_list) <- paste0("dyntoy_", gsub("\\.rds", "", gsub(".*_", "", list.files(ts_mf_dir))))
```

# Process Data & Run `tradeSeq`

We'll need to define the following function to perform quantile normalization as the `tradeSeq` authors did (see [here](https://github.com/statOmics/tradeSeqPaper/blob/master/simulation/sim2_dyntoy_multifurcating_4/20190326_evaluateDyntoyMultifurcating4.Rmd)). While `tradeSeq` uses raw expression as the response variable in its GAMs, calculating pseudotime using `slingshot` requires principal components and clusters as input, and thus we'll need to process the raw counts a bit first. 

```{r}
FQnorm <- function(counts) {
  rk <- apply(counts, 2, rank, ties.method = "min")
  counts.sort <- apply(counts, 2, sort)
  refdist <- apply(counts.sort, 1, median)
  norm <- apply(rk, 2, function(r) { refdist[r] })
  rownames(norm) <- rownames(counts)
  return(norm)
}
```

Now we'll loop through each of the 10 datasets (in parallel using `foreach`) and process them in the same way. We use `tradeSeq`'s `evaluateK()` function to adaptively determine how many knots should be used in each GAM by choosing the value of $k$ with the lowest average AIC. 

```{r}
cl <- makeCluster(4)
registerDoParallel(cl)
clusterSetRNGStream(cl, 312)
ts_res_all <- foreach(i = 1:length(ts_mf_list), 
                      .combine = "list", 
                      .multicombine = TRUE, 
                      .maxcombine = length(ts_mf_list), 
                      .export = c("FQnorm", "ts_mf_list"),
                      .packages = c("tradeSeq", "slingshot", "irlba", "bluster", "igraph")) %dopar% {
  ts_counts_norm <- FQnorm(t(ts_mf_list[[i]]$counts))
  ts_pca <- prcomp_irlba(t(ts_counts_norm), n = 3, scale. = FALSE)
  ts_graph <- makeSNNGraph(ts_pca$x, k = 30, type = "jaccard")
  ts_cl <- cluster_louvain(graph = ts_graph)$membership
  ts_lineage <- getLineages(ts_pca$x, clusterLabels = ts_cl)
  ts_crv <- getCurves(ts_lineage)
  ts_cell_weights <- slingCurveWeights(ts_crv)
  ts_pt <- slingPseudotime(ts_crv, na = FALSE)
  k_vals <- c(3:8)
  icMat <- evaluateK(counts = t(ts_mf_list[[i]]$counts),  
                     pseudotime = ts_pt, 
                     cellWeights = ts_cell_weights,
                     nGenes = 500, 
                     k = k_vals, 
                     verbose = FALSE)
  k_to_use <- k_vals[which.min(colMeans(icMat))]
  ts_gam <- fitGAM(t(ts_mf_list[[i]]$counts), 
                   pseudotime = ts_pt, 
                   cellWeights = ts_cell_weights, 
                   nknots = k_to_use, 
                   verbose = FALSE)
  ts_gam
}
stopCluster(cl)
names(ts_res_all) <- names(ts_mf_list)
```

Next we'll need to run `tradeSeq::associationTest()` on each GAM to determine whether genes are differentially expressed. We define "differentially expressed" here as the global $p$-value being less than 0.01 after adjustment using the Bonferroni correction. 

```{r}
ts_asso_test_list <- map2(.x = ts_res_all, 
                          .y = ts_mf_list, 
                          ~ associationTest(.x) %>% bind_cols(.y$tde_overall$differentially_expressed))
ts_asso_test_df <- reduce(ts_asso_test_list, bind_rows) %>% 
                   mutate(dataset = rep(names(ts_mf_list), each = 5000)) %>% 
                   setNames(nm = c("wald_stat", "df", "pvalue", "mean_log_fc", "true_de", "dataset")) %>% 
                   arrange(pvalue) %>% 
                   mutate(pvalue_adj = p.adjust(pvalue, method = "bonferroni"), 
                          ts_de = case_when(pvalue_adj < 0.01 ~ TRUE, TRUE ~ FALSE))
```

Let's check out the predictive results. 

```{r}
caret::confusionMatrix(data = as.factor(ts_asso_test_df$ts_de), 
                       reference = as.factor(ts_asso_test_df$true_de), 
                       positive = "TRUE")
```

# DE Testing Over Multiple Lineages with `scLANE`

This is a test case with just one dataset until I get all the functions working. 

```{r}
scl_counts_norm <- FQnorm(t(ts_mf_list[[1]]$counts))
scl_pca <- prcomp_irlba(t(scl_counts_norm), n = 3, scale. = FALSE)
scl_graph <- bluster::makeSNNGraph(scl_pca$x, k = 30, type = "jaccard")
scl_cl <- igraph::cluster_louvain(graph = scl_graph)$membership
scl_lineage <- getLineages(scl_pca$x, clusterLabels = scl_cl)
scl_crv <- getCurves(scl_lineage)
scl_cell_weights <- slingCurveWeights(scl_crv)
scl_pt <- slingPseudotime(scl_crv)
```

prep data

```{r}
library(scLANE)
pt_df <- as.data.frame(scl_pt) %>% 
         rename(PT1 = curve1, PT2 = curve2) %>% 
         mutate(across(everything(), function(x) x / max(x, na.rm = TRUE)))
sim_counts <- ts_mf_list[[1]]$counts
set.seed(312)
samp_idx <- sample(1:ncol(sim_counts), 10)
gene_stats <- testDynamic(expr.mat = sim_counts[, samp_idx], 
                          pt = pt_df)
```


```{r}
getResultsDE <- function(test.dyn.results = NULL, p.adj.method = "bonferroni", fdr.cutoff = 0.01) {
  if (is.null(test.results)) stop("Please provide a result list.")
  result_df <- purrr::map(test.dyn.results, function(x) data.frame(x[1:9])) %>%
               purrr::reduce(rbind) %>% 
               dplyr::arrange(P_Val) %>%
               dplyr::mutate(P_Val_Adj = stats::p.adjust(P_Val, method = p.adj.method),
                             Gene_Dynamic_Lineage  = case_when(P_Val_Adj < fdr.cutoff ~ 1, TRUE ~ 0)) %>%
               dplyr::with_groups(Gene, dplyr::mutate, Gene_Dynamic_Overall = max(Gene_Dynamic_Lineage)) %>% 
               dplyr::relocate(Gene, Lineage, LRT_Stat, P_Val)
  return(result_df)
}

a <- gene_stats[[1]]
names(a[[1]])
b <- purrr::reduce(purrr::map(a, function(x) data.frame(x[1:9])), rbind)
purrr::map(a, function(x) data.frame(x[1:9])) %>%
               purrr::reduce(rbind) %>% 
               dplyr::arrange(P_Val) %>%
               dplyr::mutate(P_Val_Adj = stats::p.adjust(P_Val, method = "BH"),
                             Gene_Dynamic_Lineage  = case_when(P_Val_Adj < .01 ~ 1, TRUE ~ 0)) %>%
               dplyr::with_groups(Gene, dplyr::mutate, Gene_Dynamic_Overall = max(Gene_Dynamic_Lineage)) %>% 
               dplyr::relocate(Gene, LRT_Stat, P_Val)
```

